# HESA
Federated Learning (FL) trains a machine learning model on distributed clients without exposing individual data. However, recent research has proved that privacy issues exist due to the leakage of gradient. To solve this problem, secure aggregation technology comes out, which enables a server to learn the sum of the uploaded gradients without revealing their confidential information. However, due to limitations in the algorithmic primitives and flaws in the protocol design, the straightforward application of these technologies often results in suboptimal outcomes, such as failing to adequately protect data privacy or achieving privacy at the cost of system inefficiency. In this study, we introduce HESA, a Highly Efficient Secure Aggregation method for FL with significant efficiency superiority over existing state-of-the-art methods, which simultaneously ensures data privacy and high training efficiency. On the one hand, HESA not only protect model privacy for clients via masking techniques but also actively defends against privacy attacks resulting from collusion among a majority of compromising participants. On the other hand, HESA introduces a new way to reduce communication overhead by optimizing the computational protocols in the online phase and reducing the number of interactions between clients and the server. Compared with the state-of-the-art method FLDP, empirical results show that HESA is 40$\%$ faster than FLDP with the equivalent accuracy while preserving data privacy under both semi-honest and malicious threat models.

